# Step 1: Import the necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.impute import SimpleImputer

# Step 2: Load the data
df = pd.read_csv('/content/fraudTrain.csv')
df = pd.read_csv('/content/fraudTrain.csv', header = 0)
print(df.head())

# Step 3: Select only the numeric columns for scaling, excluding the target variable 'is_fraud'
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns.drop('is_fraud')

# Step 4: Split the data into features and target variable
X = df[numeric_columns]  # Keep only numeric columns
y = df['is_fraud']  # Target variable

# Step 5: Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Step 6: Remove rows with missing target values from both X and y
# Get the indices of rows with non-missing target values
valid_indices = ~y.isna()

# Select the corresponding rows in X_imputed and y
X_imputed = X_imputed[valid_indices]
y = y[valid_indices]

# Step 7: Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=42)

# Step 8: Scale the features using StandardScaler
scaler = StandardScaler()

# Fit the scaler on the training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data using the same scaler
X_test_scaled = scaler.transform(X_test)

# Step 9: Train a logistic regression model
log_reg = LogisticRegression(random_state=42)
log_reg.fit(X_train_scaled, y_train)

# Step 10: Train a decision tree classifier
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train_scaled, y_train)

# Step 11: Train a random forest classifier
random_forest = RandomForestClassifier(random_state=42)
random_forest.fit(X_train_scaled, y_train)

# Step 12: Make predictions on the test set
y_pred_log_reg = log_reg.predict(X_test_scaled)
y_pred_decision_tree = decision_tree.predict(X_test_scaled)
y_pred_random_forest = random_forest.predict(X_test_scaled)

# Step 13: Evaluate the models

# Logistic Regression
print("Logistic Regression - Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_log_reg))
print("\nLogistic Regression - Classification Report:")
print(classification_report(y_test, y_pred_log_reg))

# Decision Tree
print("Decision Tree - Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_decision_tree))
print("\nDecision Tree - Classification Report:")
print(classification_report(y_test, y_pred_decision_tree))

# Random Forest
print("Random Forest - Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_random_forest))
print("\nRandom Forest - Classification Report:")
print(classification_report(y_test,y_pred_random_forest  ))
